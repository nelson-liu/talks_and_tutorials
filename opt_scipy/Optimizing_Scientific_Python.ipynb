{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nelson Liu \n",
      "last updated: 2016-08-21 20:51:57 \n",
      "\n",
      "CPython 2.7.12\n",
      "IPython 5.1.0\n",
      "\n",
      "numpy 1.11.1\n",
      "scipy 0.18.0\n",
      "sklearn 0.17.1\n",
      "cython 0.24.1\n",
      "numba 0.27.0\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)\n",
      "system     : Darwin\n",
      "release    : 15.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Nelson Liu\" -d -n -t -u -v -p numpy,scipy,sklearn,cython,numba -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimizing Scientific Python\n",
    "## + other neat tools to make your life easier!  \n",
    "Nelson Liu  \n",
    "August 22, 2016\n",
    "\n",
    "[download tutorial materials here](https://github.com/nelson-liu/talks_and_tutorials/tree/master/opt_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> \"Premature optimization is the root of all evil\"  \n",
    ">\n",
    "> ~ Donald Knuth\n",
    "  \n",
    "  \n",
    "Optimized code is more complicated, which leads to it being harder to debug if problems arise!  \n",
    "\n",
    "Optimizing too early leads to greater development costs further down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Motivating Example / Early Optimization Steps\n",
    "  - using list comprehensions and NumPy\n",
    "- Why Python?\n",
    "- Deeper Optimization\n",
    "  - \"Low\" hanging fruit: JIT Compilers\n",
    "    - Numba and PyPy\n",
    "  - More complex: C extensions\n",
    "    - Cython\n",
    "- Multiprocessing and Multithreading\n",
    "  - Cython and the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivating Example: Cosine Distance  / Analogies\n",
    "\n",
    "- Given two vectors, find the angle between them\n",
    "- Commonly used in semantic similarity tasks; words represented by vectors with a smaller angle of separation are generally \"closer\" in semantic meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given vectors $A$ and $B$, the cosine similarity is calculated with the dot product and magnitude.\n",
    "$$similarity = cos(\\theta) = \\frac{A \\cdot B}{\\left|\\left|A\\right|\\right| \\left|\\left|B\\right|\\right|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The analogy prediction task is defined as follows: given a word pair ($w_a, w_b$) (i.e. man, woman) and another\n",
    "word $w_c$ (i.e. king), predict the best word $w_d$ (i.e. queen) such that the pair ($w_c, w_d$) has\n",
    "similar relation to ($w_a$, $w_b$).\n",
    "\n",
    "Namely, to get the solution for an analogy $w_d$:\n",
    "$$X = vector(w_b) − vector(w_a) + vector(w_c)$$\n",
    "$$w_d = argmax_{w \\in V \\forall w \\notin \\{w_a, w_b, w_c\\}} {cos(vector(w), X)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### For didactic purposes, we'll implement an analogy solver in plain Python first, then go about ways to speed it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's start by getting some GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "import numpy as np\n",
    "import urllib2\n",
    "\n",
    "# if you have pickled GloVe vectors already, feel free to replace ``None`` with\n",
    "# a path to a dictionary of word vectors.\n",
    "# The pickle file I've provided only includes words in the English language as \n",
    "# judged by an online dictionary.\n",
    "local_path = \"./data/glove.840B.300d.pkl\"\n",
    "if local_path == None:\n",
    "    # download pickled word vectors\n",
    "    pickled_vectors = urllib2.urlopen(\"http://www.nelsonliu.me/files/glove.840B.300d.pkl\")\n",
    "    glove_vecs = pickle.load(pickled_vectors)\n",
    "else:\n",
    "    glove_vecs = pickle.load(open(local_path,\"rb\"))\n",
    "    \n",
    "vocabulary = glove_vecs.keys()\n",
    "\n",
    "# the dictionary is {word:list}, let's make it {word:ndarray}\n",
    "# feel free to comment this out if you don't need it\n",
    "for word in vocabulary:\n",
    "    glove_vecs[word] = np.array(glove_vecs[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's write a preliminary naïve Python implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_sim_py_naive(A, B):\n",
    "    # calculate the dot product\n",
    "    dot_prod = 0\n",
    "    mag_A = 0\n",
    "    mag_B = 0\n",
    "    for i in xrange(len(A)):\n",
    "        dot_prod += A[i]*B[i]\n",
    "        mag_A += A[i]*A[i]\n",
    "        mag_B += B[i]*B[i]\n",
    "    mag_A = math.sqrt(mag_A)\n",
    "    mag_B = math.sqrt(mag_B)\n",
    "    \n",
    "    return dot_prod / (mag_A * mag_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We'll use this method to calculate analogies given `w_a`, `w_b`, `w_c`, and a cosine similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_analogies(w_a, w_b, w_c, cosine_sim_func):\n",
    "    # get the vectors corresponding to the words\n",
    "    A = glove_vecs[w_a]\n",
    "    B = glove_vecs[w_b]\n",
    "    C = glove_vecs[w_c]\n",
    "    X = np.add(np.subtract(B, A), C)\n",
    "    \n",
    "    max_cosine_similarity = -1\n",
    "    w_d = None\n",
    "    \n",
    "    for w_d_candidate in vocabulary:\n",
    "        if (w_d_candidate == w_a or \n",
    "            w_d_candidate == w_b or \n",
    "            w_d_candidate == w_c):\n",
    "            continue\n",
    "        D_candidate = glove_vecs[w_d_candidate]\n",
    "        cos_similarity = cosine_sim_func(X, D_candidate)\n",
    "        if cos_similarity > max_cosine_similarity:\n",
    "            max_cosine_similarity = cos_similarity\n",
    "            w_d = w_d_candidate\n",
    "    return w_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's time this baseline, wow-I-can't-believe-someone-wrote-this implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 50.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "# this code snippet might take a while to run...\n",
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Wow, that's atrocious! Let's think about some basic ways to optimize it\n",
    "### For some background: this very task was actually one part of a undergrad NLP homework assignment; we had to solve 10k+ analogies using at least 2 types of pre-trained embeddings. With a runtime like the above for just one analogy, it's no wonder some students spent several days running their code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# List comprehensions are your friend! \n",
    "- Not only do they make your code more concise, they're faster!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim_py_comprehension(A, B):\n",
    "    # calculate the dot product\n",
    "    results = [sum(x) for x in zip(*[(i*j, i*i, j*j) for i,j in zip(A, B)])]\n",
    "    dot_prod = results[0]\n",
    "    mag_A = math.sqrt(results[1])\n",
    "    mag_B = math.sqrt(results[2])\n",
    "    \n",
    "    return dot_prod / (mag_A * mag_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 31.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_comprehension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That's a pretty sizeable speedup! Now, it'd only take us 81 hours! Jests aside, list comprehensions do offer significant speedup over verbose loops. However, keep in mind that complex list comprehensions can be hard to interpret when you dust off your code 3 months down the line.\n",
    "- A big reason why this code is so slow with loops is because of Python's dynamic type checking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's take a look at some other strategies we can use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Use Numpy Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Why are Numpy Arrays / their functions fast?\n",
    "- Densely packed, and of homogenous type\n",
    "  - On the other hand, Python lists are arrays of pointers to objects\n",
    "  - This gives NumPy the advantage of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference)\n",
    "  \n",
    "- Most operations are implemented in C\n",
    "  - Avoids costly dynamic type checking, which really made our previous implementation slow.\n",
    "  \n",
    "- Gateway to more optimizations with things like Numba, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's use numpy functions to try to speed this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim_py_numpy(A, B):\n",
    "    # calculate the dot product\n",
    "    dot_prod = np.dot(A,B)\n",
    "    # calculate the product of magnitudes\n",
    "    mag_A = np.linalg.norm(A) \n",
    "    mag_B = np.linalg.norm(B)\n",
    "    \n",
    "    return dot_prod / (mag_A * mag_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.56 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Numpy functions gave us a great speedup, as the `dot_prod` and `lingalg.norm` methods use [broadcasting](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) to loop over the data structure at the C level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lets try some libraries that directly implement cosine similarity or similar routines, and compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scipy Cosine Distance-Based Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cosine_sim_py_scipy(A, B):\n",
    "    return 1 - spatial.distance.cosine(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 5.42 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# scikit-learn Cosine Similarity Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_sim_py_sklearn(A, B):\n",
    "    return cosine_similarity(A.reshape(1,-1), B.reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 22.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "# this is actually surprisingly bad, i've taken it upon myself to see why this is happening\n",
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Checkpoint\n",
    "It seems like our custom method using numpy is the fastest; this makes sense, since the implementations in scikit-learn and scipy have to cater to move than just `ndarray`s and thus spend some time doing validation / other checks.\n",
    "\n",
    "At this point, we've reached the point that most developers / researchers would get to. It's likely that at this point, we'd just run the our analogy solver and go sleep / do other things for a few hours or days.\n",
    "\n",
    "However, we can do much better than our current performance by tapping into some other external tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intermezzo: Why bother using Python in the first place?\n",
    "\n",
    "If all you care about is performance, you should not be using Python; bare-metal languages like C / C++ are probably more suited to that singular need.  \n",
    "\n",
    "However, rarely do we only care about performance. Development speed, maintainability, useability, and scalability are all important considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Python (or mostly-Python) code is easier to read, maintain, and contribute to!\n",
    "  - This is especially important for replicability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Python-based tools are easy to run anywhere\n",
    "    - (Generally) No complicated install or build process required, just setup a {virtual|conda}env, pip install the things you need, and off you go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# JIT Compilers -- minimal effort, potentially lots of reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Good first place to start if you don't want to work a lot (so, everyone)\n",
    "  - Requires minimal change to your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Two main methods in the Python:\n",
    "  - PyPy: fast, compliant, alternate implementation of the Python language (2.7, 3.5)\n",
    "  - Numba: NumPy aware dynamic Python compiler using LLVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PyPy, in short\n",
    "\n",
    "> \"If you want your code to run faster, you should probably just use PyPy.\"  \n",
    ">\n",
    "> ~ Guido van Rossum (creator of Python)\n",
    "\n",
    "- Essentially Python, but with a JIT compiler. \n",
    "  - Passes the CPython (the standard implementation of Python) test suite\n",
    "\n",
    "Unfortunately, it's not fully compatible with NumPy yet, which makes it of limited use to us. It's quite interseting though, and may be game-changing when the SciPy stack is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Numba\n",
    "\n",
    "> Numba is a mechanism for producing machine code from Python syntax and typed data structures such as those that exist in NumPy.\n",
    ">\n",
    "> ~ [Numba Repo](https://github.com/numba/numba)\n",
    "\n",
    "- Requires minimal modification to code\n",
    "  - just add a `jit` decorator to the methods you want to compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Installation / Setup\n",
    "\n",
    "- Numba uses LLVM, a compilation framework\n",
    "  - which means you need LLVM to run numba, which prevents you from simply doing `pip install numba` in most cases.\n",
    "  - I hear it works quite well with `conda` though, if you use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Installation on OS X with `brew`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "brew install homebrew/versions/llvm38 --with-rtti\n",
    "git clone https://github.com/numba/llvmlite\n",
    "cd llvmlite\n",
    "LLVM_CONFIG=/usr/local/Cellar/llvm38/3.8.0/bin/llvm-config-3.8 python setup.py install\n",
    "LLVM_CONFIG=/usr/local/Cellar/llvm38/3.8.0/bin/llvm-config-3.8 pip install numba\n",
    "cd ..\n",
    "rm -rf llvmlite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Installation on Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The instructions below assume you have `clang` and thus `llvm` on your machine\n",
    "  - If you don't, see if you can ask a system admin to install it `llvm`.\n",
    "  - Alternatively, you can build `clang` (`llvm` is a dep of clang) in your local directory\n",
    "    - This sounds like a horrible experience, though. If you do end up doing such a thing, please let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "git clone https://github.com/numba/llvmlite\n",
    "cd llvmlite\n",
    "LLVM_CONFIG=<llvm config file> python setup.py install\n",
    "LLVM_CONFIG=<llvm config file> pip install numba\n",
    "cd ..\n",
    "rm -rf llvmlite\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "more info [here](http://stackoverflow.com/questions/28782512/getting-python-numba-working-on-ubuntu-14-10-or-fedora-21-with-python-2-7), I haven't tried a linux install yet so please let me know if you get one to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's try out Numba on our code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numba.decorators import jit\n",
    "\n",
    "cosine_sim_py_numba = jit(cosine_sim_py_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 280 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## A simple Numba wrapper sped up our original code by ~175x! This is even ~5.5x faster than the function with Numpy.\n",
    "## With Numba, one could expect to see even greater increases in speed if you have a bunch of nested for loops or the like, since they'd all get turned into machine code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## It's worth noting that all the code we've written so far is still pure Python\n",
    "## Our Numba function is probably very close to the extent you can push this function without mathematical / algorithmic tricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Some Numba Tips\n",
    "\n",
    "- It's important to think about what you're optimizing. For example, notice that we chose to optimize our naive Python implementation. Why not optimize our fast numpy implementation, to make it even faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cosine_sim_py_numpy_numba = jit(cosine_sim_py_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.12 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_py_numpy_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see, running the NumPy implementation with Numba gave us no performance boosts; in fact, our code got a bit slower!\n",
    "  - If you think about it though, this makes perfect sense\n",
    "  - The numpy operations internally already use C functions, so the JIT does not help it at all\n",
    "    - In extreme cases (e.g. this one), the small performance cost added by using Numba is even greater than the optimizations, because the original code is already compiled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- just calling `jit` directly on the callable generally leads to pretty good results, but there are cases where slowdowns may incur because the C code is forced to fall back on a Python object or the like. \n",
    "  - The less Python objects you use, the more `jit` can do for you!\n",
    "  - numpy arrays are an exception to this rule, because we'll see later that it's quite simple to use them in C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# C/C++ Extensions to Python\n",
    "\n",
    "- It's possible to write C code that can be imported to Python as a module, which is quite useful from an efficiency standpoint.\n",
    "  - Python calls these \"extensions\" or \"extension modules\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is what they (roughly) look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Python Code\n",
    "\n",
    "```\n",
    "import some_c_module\n",
    "result = some_c_module.some_method()\n",
    "```\n",
    "\n",
    "C Code\n",
    "```\n",
    "static PyObject * some_c_module(PyObject *self)\n",
    "{\n",
    "    // some method\n",
    "    return Py_BuildValue(\"i\", result);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This is is generally pretty painful to do, and I wouldn't advise writing C code for use in Python in this way. However, making your own C extensions can be quite useful if you have pre-written code in C and want to have a Python wrapper. There's a pretty good tutorial on doing that [here](http://dan.iel.fm/posts/python-c-extensions/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In most cases, you won't have prewritten C code to use.\n",
    "  - But you still want to optimize your code!\n",
    "  - But you don't want to dive down the rabbit hole of C extensions / the Python-C API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cython is here for you!\n",
    "\n",
    ">Cython is an optimising static compiler for both the Python programming language and the extended Cython programming language (based on Pyrex). It makes writing C extensions for Python as easy as Python itself.\n",
    ">\n",
    "> [Cython documentation](http://cython.org/)\n",
    "\n",
    "- It's easy to see that Cython is quite different than Numba. \n",
    "  - For one, Cython requires a separate compilation step before running your Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Let's try writing porting our code to Cython\n",
    "\n",
    "- I'll use the opportunity to demonstrate everything I wish I knew about Cython when I was first starting out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Cython Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from __future__ import division\n",
    "# \"cimport\" is used to import special compile-time information about the numpy module\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "@cython.boundscheck(False) # turn off bounds-checking for entire function\n",
    "@cython.wraparound(False) # turn off wrap around for entire function\n",
    "def cosine_sim_cython(double[:] A, double[:] B):\n",
    "    cdef size_t i\n",
    "    cdef double dot_product = 0.0\n",
    "    cdef double mag_A = 0.0\n",
    "    cdef double mag_B = 0.0\n",
    "\n",
    "    # let's rewrite the dot product without numpy\n",
    "    # and calculate the magnitude in the same loop\n",
    "    for i in range(A.shape[0]):\n",
    "        dot_product += A[i] * B[i]\n",
    "        mag_A += A[i] * A[i]\n",
    "        mag_B += B[i] * B[i]\n",
    "    mag_A = sqrt(mag_A)\n",
    "    mag_b = sqrt(mag_B)\n",
    "    return dot_product / (mag_A * mag_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 448 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies(\"man\", \"woman\", \"king\", cosine_sim_cython)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Note that the performance of our preliminary Cython implementation was slower than Numba\n",
    "\n",
    "## and we did a lot more work too!\n",
    "\n",
    "- However, Cython is powerful because you can choose how low-level you want your code to be. The code above, while it is still Cython, makes use of Python objects which slows down the performance. What if we completely turned off Python?\n",
    "  - One way of doing this is by removing the GIL. This also gives us the benefit of having easily parallelizable code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What's the Global Interpreter Lock (GIL)?\n",
    "\n",
    "- the GIL is a mutex that prevents multiple native threads from executing Python bytecodes at once\n",
    "  - In English, it's a \"lock\" that prevents a Python program from executing multiple threads at the same time.\n",
    "  - This is necessary because Python's memory is not thread safe!\n",
    "  - This prevents efficient multi-threading in Python.\n",
    "      - People use multiprocessing to get around this, but spawning processes is more expensive than spawning threads / they have different memory pools and have to pass objects between each other\n",
    "\n",
    "- In Cython, you can remove the GIL to easily run your code at the C-level with multithreading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Removing the GIL\n",
    "\n",
    "- In order for code to run with `nogil`, it must satisfy several constraints\n",
    "  - Only uses statically typed variables of C primitives (e.g. int, long, double, size_t)\n",
    "  - Arrays must be represented using pointers (goodbye, numpy arrays!)\n",
    "  - No Python objects or Python methods can be used at all\n",
    "  - All functions must have `nogil` at the end of their definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# But wait, how are we going to use our data without numpy arrays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fortunately, you can easily extract a pointer to the underlying numpy array and it's dtype\n",
    "```\n",
    "cdef dtype* X_pointer = <dtype*> X_numpyarray.data\n",
    "```\n",
    "- Since we're using doubles here, we have to set the type as such:\n",
    "```\n",
    "cdef double* X_pointer = <double*> X_numpyarray.data\n",
    "```\n",
    "- Lastly, the original numpy array must be cast as such, explicitly\n",
    "```\n",
    "cdef double* X_pointer = <double*> (<numpy.ndarray> X_numpyarray).data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# An alternate solution: `MemoryViews`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- typed `MemoryViews` allow you to efficiently access data buffers (e.g. those underlying numpy arrays) without Python overhead\n",
    "  - `MemoryView` array of doubles : `cdef double [:] <identifier>`\n",
    "  - `MemoryView` 2d array of ints: `cdef int [:, :] <identifier>`\n",
    "  - The Cython userguide has [a great page](http://cython.readthedocs.io/en/latest/src/userguide/memoryviews.html) explaining and showing examples of using `MemoryViews`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's write a Cython `nogil`-compatible version of our analogy solver\n",
    "- We have to be a bit creative with our data because strings are Python objects, and thus not allowed in `nogil`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_analogies_cython(w_a, w_b, w_c):\n",
    "    # get the vectors corresponding to the words\n",
    "    A = glove_vecs[w_a]\n",
    "    B = glove_vecs[w_b]\n",
    "    C = glove_vecs[w_c]\n",
    "\n",
    "    nd_vectors = np.array(glove_vecs.values())\n",
    "    return glove_vecs.keys()[calculate_analogies_cython_helper(w_a, w_b, w_c, A, B, C, nd_vectors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# And now for the `nogil` Cython methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: /Users/nfliu/.ipython/cython/_cython_magic_ec1c2bd3bdb74fe2ac786ce13a912192.pyx:65:10: Unsigned index type not allowed before OpenMP 3.0\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "from __future__ import division\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport sqrt\n",
    "from cython.parallel cimport prange, parallel\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def calculate_analogies_cython_helper(str w_a, str w_b, str w_c,\n",
    "                                      double [:] A_memview, double [:] B_memview,\n",
    "                                      double [:] C_memview, double [:,:] vectors_memview):\n",
    "    # build the X array for comparison\n",
    "    cdef double[:] X_memview = np.add(np.subtract(B_memview, A_memview), C_memview)\n",
    "\n",
    "    # hardcoded variable for dimensions, figure it out dynamically if i have time to\n",
    "    # come back and change it\n",
    "    cdef size_t dimensions = 300\n",
    "\n",
    "    # keep track of the max cosine similarity and the index of its associated w_d\n",
    "    cdef double max_cosine_similarity = -1.0\n",
    "    cdef size_t w_d_idx = -1\n",
    "\n",
    "    # temp variable for the word vector we're currently comparing\n",
    "    cdef double[:] d_candidate\n",
    "    cdef double[:] similarities\n",
    "    cdef double d_cos_similarity\n",
    "\n",
    "    # keep track of the number of vectors\n",
    "    cdef size_t num_vectors = vectors_memview.shape[0]\n",
    "\n",
    "    # temp variable for iteration, since we can't dynamically generate them\n",
    "    # in the loop declaration\n",
    "    cdef size_t i = 0\n",
    "    with nogil:\n",
    "        for i in range(num_vectors):\n",
    "            if(memview_equals(vectors_memview[i], A_memview, dimensions)\n",
    "               or memview_equals(vectors_memview[i], B_memview, dimensions)\n",
    "               or memview_equals(vectors_memview[i], C_memview, dimensions)):\n",
    "                continue\n",
    "            d_cos_similarity = cosine_sim_cython_nogil(vectors_memview[i], X_memview, dimensions)\n",
    "            if d_cos_similarity > max_cosine_similarity:\n",
    "                max_cosine_similarity = d_cos_similarity\n",
    "                w_d_idx = i\n",
    "\n",
    "    return w_d_idx\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef bint memview_equals(double[:] X, double[:] Y, size_t size) nogil:\n",
    "    cdef size_t i\n",
    "\n",
    "    for i in range(size):\n",
    "        if X[i] != Y[i]:\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef double cosine_sim_cython_nogil(double[:] A, double[:] B, size_t size) nogil:\n",
    "    cdef size_t i\n",
    "    cdef double dot_product = 0.0\n",
    "    cdef double mag_A = 0.0\n",
    "    cdef double mag_B = 0.0\n",
    "\n",
    "    for i in prange(size, schedule='guided', num_threads=4):\n",
    "        dot_product += A[i] * B[i]\n",
    "        mag_A += A[i] * A[i]\n",
    "        mag_B += B[i] * B[i]\n",
    "    mag_A = sqrt(mag_A)\n",
    "    mag_b = sqrt(mag_B)\n",
    "    return dot_product / (mag_A * mag_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Phew, that was a lot of work! Let's time it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 398 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit calculate_analogies_cython(\"man\", \"woman\", \"king\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In terms of speed gains, they were marginal at best\n",
    "  - This makes a bit of sense, considering that the speed we get from multithreading in this case is mostly offset by the cost of creating threads\n",
    "- Possible suggestions for increasing speed\n",
    "  - not checking `MemoryView` equality but comparing Strings instead.\n",
    "    - How do we get around the fact that strings are objects?\n",
    "  - At this point, we have pretty good performance for `calculate_analogies`\n",
    "    - There's little headroom to exploit, so we're much better served (in terms of overall performance) parallelizing the operation of calculating more than one analogy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Demo: Building Cython in your project / a look into generated files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parting Thoughts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### General Speedup Tips\n",
    "- Cache constant values in loops and avoid recalculation\n",
    "  - related: cache values in between loops if you can. Ask if you've calculated something before calculating it again.\n",
    "- If you're only trying to find the argmax, remove scalars from your equation\n",
    "- Use numpy! It's pretty good\n",
    "- Finally, use a JIT or Cythonize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Thoughts about where to place your optimization efforts\n",
    "- I had heard about Numba here and there at Scipy, but I never used it until I was making the material for this presentation. Needless to say, I'm extremely impressed by what it can do for single-thread code.\n",
    "  - One simple modification to our call increased the speed by 175x.\n",
    "  - It'd be great to see automatic parallelization; they're already [bringing in some constructs to help with that](http://numba.pydata.org/numba-doc/0.11/prange.html)\n",
    "  - If you use Numba and get good (or bad) results, let me know! I think it could very well be the future of scientific computing.\n",
    "- However, Cython still has its place for bringing easily-parallelizable loops with OpenMP"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
